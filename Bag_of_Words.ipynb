{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM217ECfPqwSaa+6KYvW40S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amithrx/amithrx-Bag-of-words-based-matching-on-the-MNIST-fashion-datasets/blob/main/Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoTS8pfw1XU7",
        "outputId": "6e7b936d-1fdf-4e4f-dfad-700e8cadd11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.6.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "print(cv2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(trainImageData,trainImageLabel), (testImageData,testImageLabel) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "2XmRXHCS1-UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "R1tYHDh22Gcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_features_set(ImageData):\n",
        "  '''\n",
        "  Returns feature vector containing descriptors corresponding to given image vector\n",
        "  '''\n",
        "  sift = cv2.xfeatures2d.SIFT_create()\n",
        "  imageDescriptor = []\n",
        "  length = len(ImageData)\n",
        "  for i in range(length):\n",
        "    img = ImageData[i]\n",
        "    image8bit = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
        "    k,d = sift.detectAndCompute(image8bit,None)\n",
        "    if d is None: imageDescriptor.append([])\n",
        "    else : imageDescriptor.append(list(d))\n",
        "  return imageDescriptor"
      ],
      "metadata": {
        "id": "d2Mv2hOvifN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Merge_features(descriptorSet):\n",
        "  '''\n",
        "  To combine all the features in given descriptorSet to a single Descriptor array\n",
        "  '''\n",
        "  Descriptors = []\n",
        "  length = len(descriptorSet)\n",
        "  for i in range(length):\n",
        "    descriptorLength = len(descriptorSet[i])\n",
        "    for j in range(descriptorLength):\n",
        "      Descriptors.append(descriptorSet[i][j])\n",
        "  return np.array(Descriptors)"
      ],
      "metadata": {
        "id": "Io2IUv0zilUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Centroid(cluster): \n",
        "  '''\n",
        "  Returns the centroid of a particular cluster\n",
        "  '''\n",
        "  cluster = np.array(cluster)\n",
        "  return np.mean(cluster,axis = 0)\n"
      ],
      "metadata": {
        "id": "PiEa4rsJUDkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Nearest_centroid(data,centroids):\n",
        "  '''\n",
        "  Returns the index of the nearest centroid of a feature descriptor \n",
        "  '''\n",
        "  k = len(centroids)\n",
        "  differenceArray = []\n",
        "  for i in range(k):\n",
        "    differenceArray.append(np.linalg.norm(data-centroids[i]))\n",
        "  differenceArray = np.array(differenceArray)\n",
        "  return int(differenceArray.argmin())"
      ],
      "metadata": {
        "id": "hV-p7nnqonpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Initialize_centroid(k,descriptors):\n",
        "  '''\n",
        "      Initialising k centroids of the feature descriptor\n",
        "      Used KMeans++ algorithm for initializing the centroid,\n",
        "      where in next iteration we will choose randomly the points with probability assigned to each descriptors\n",
        "  '''\n",
        "  n = len(descriptors)\n",
        "  x = list(np.random.choice(n,size = 1,replace = False))\n",
        "  ret = []\n",
        "  ret.append(descriptors[x[0],::])\n",
        "  for i in range(k-1):\n",
        "    D = [0]*n\n",
        "    W = [0]*n\n",
        "    total = 0\n",
        "    for j in range(n):\n",
        "      nearest = ret[Nearest_centroid(descriptors[j,::],ret)]\n",
        "      D[j] = np.linalg.norm(descriptors[j,::]-nearest)\n",
        "      total += D[j]**2\n",
        "    for j in range(n):\n",
        "      W[j] = (D[j]**2)/total\n",
        "    x = list(np.random.choice(n,size = 1,replace = False,p = W))\n",
        "    ret.append(descriptors[x[0],::])\n",
        "  #   print(ret)\n",
        "  return np.array(ret)"
      ],
      "metadata": {
        "id": "Ef6PxYiYiyAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kMean_clustering(k,centroids,descriptors):\n",
        "  '''\n",
        "  Running Single Iteration of a K-mean clustering\n",
        "  '''\n",
        "  n = len(descriptors)\n",
        "  color = [0]*n\n",
        "  for i in range(n):\n",
        "    color[i] = Nearest_centroid(descriptors[i],centroids)    \n",
        "  newCentroids = []\n",
        "  cluster = {}\n",
        "  for i in range(k): cluster[i] = []\n",
        "  for j in range(n): cluster[color[j]].append(descriptors[j])\n",
        "  for i in range(k):\n",
        "    newCentroids.append(Centroid(cluster[i]))\n",
        "  return (color,np.array(newCentroids))  "
      ],
      "metadata": {
        "id": "BGVuWfMcoxKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Get_true_descriptor(centroids,descriptors):\n",
        "  '''\n",
        "  Getting the nearest descriptor to each centroids obtained \n",
        "  '''\n",
        "  k = len(centroids)\n",
        "  realRep = []\n",
        "  for i in range(k):\n",
        "    realRep.append(descriptors[Nearest_centroid(centroids[i],descriptors)])\n",
        "  return realRep"
      ],
      "metadata": {
        "id": "99Tt4coLo4fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ComputeHistogram(clusterCentroids,imageDescriptor):\n",
        "  '''\n",
        "  Creating Histogram for every images in sets\n",
        "  '''\n",
        "  Histogram=[]\n",
        "  length = len(imageDescriptor)\n",
        "  for i in range(length):\n",
        "    descriptors = imageDescriptor[i]\n",
        "    k = len(clusterCentroids)\n",
        "    descriptorNum=len(descriptors)\n",
        "    frequencyVector=np.zeros(k)\n",
        "    for j in range(descriptorNum):\n",
        "      frequencyVector[Nearest_centroid(descriptors[j],clusterCentroids)]+=1\n",
        "    Histogram.append(frequencyVector)\n",
        "  return np.array(Histogram)"
      ],
      "metadata": {
        "id": "ayAtO4FSo_8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Count_image_containing_visual_word(histogramSet):\n",
        "  '''\n",
        "  Storing total count of images which contain visual word i\n",
        "  '''\n",
        "  k = histogramSet.shape[1]\n",
        "  count = np.zeros(k)\n",
        "  for histogram in histogramSet:\n",
        "    for i in range(k):\n",
        "      if histogram[i] > 0: count[i]+=1\n",
        "  return count"
      ],
      "metadata": {
        "id": "tGuJh5LapCyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Normalize_histogram(histogramSet,countImages):\n",
        "  '''\n",
        "  Normalizing the histogram, by assigning more weight to particular word as compared to other weight \n",
        "  by using TF-IDF methods\n",
        "  '''\n",
        "  newHistogramSet = []\n",
        "  for histogram in histogramSet:\n",
        "    nd = 0\n",
        "    N = len(histogramSet)\n",
        "    k = len(histogram)\n",
        "    for i in range(k):\n",
        "      if histogram[i] > 0: nd+=1\n",
        "    for i in range(k):\n",
        "      if nd == 0 or countImages[i] == 0: histogram[i] = 0\n",
        "      else :histogram[i] = (histogram[i]/nd)*(math.log(N/countImages[i]))\n",
        "    newHistogramSet.append(histogram)\n",
        "  return np.array(newHistogramSet)"
      ],
      "metadata": {
        "id": "ALfKVs5apIiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MatchHistogram(A,B): \n",
        "  '''\n",
        "  Computing the cosine similarity of two images using their histogram\n",
        "  '''\n",
        "  a = np.linalg.norm(A)\n",
        "  b = np.linalg.norm(B)\n",
        "  if a == 0:\n",
        "    if b == 0: return 0\n",
        "    else: return 1\n",
        "  elif b == 0: return 1\n",
        "  return 1 - (np.dot(A,B))/(a)/(b)"
      ],
      "metadata": {
        "id": "RMdgLCMIpLxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy(trainImageLabels,testImageLabels,trainHistogramSet,testHistogramSet,kk):\n",
        "  '''\n",
        "  Getting accuracy\n",
        "  '''\n",
        "  n = len(trainImageLabels)\n",
        "  m = len(testImageLabels)\n",
        "  # m=100\n",
        "  predicted = [0]*m\n",
        "  for i in range(m):\n",
        "    freq = [0]*10\n",
        "    freq = np.array(freq)\n",
        "    differenceArray = []\n",
        "    print(\"Image\" + str(i) + \" test\")\n",
        "    for j in range(n):\n",
        "      differenceArray.append(MatchHistogram(testHistogramSet[i],trainHistogramSet[j]))\n",
        "    differenceArray = np.array(differenceArray)\n",
        "    maxIndices = np.argsort(differenceArray)\n",
        "    for j in range(kk):\n",
        "      freq[trainImageLabels[maxIndices[j]]] += 1\n",
        "    x = freq.argmax()\n",
        "    for j in range(10):\n",
        "      if freq[x] == freq[j]:\n",
        "        predicted[i]=j\n",
        "\n",
        "  return predicted"
      ],
      "metadata": {
        "id": "i3HAb2R2pSK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def accuracy2(trainImageLabels,testImageLabels,trainHistogramSet,testHistogramSet,kk):\n",
        "#   n = len(trainImageLabels)\n",
        "#   m = len(testImageLabels)\n",
        "#   # m=100\n",
        "#   predicted = [0]*m\n",
        "#   positive = 0\n",
        "#   classwise=[0]*10\n",
        "#   total_classwise = [0]*10\n",
        "#   true_positive = [0]*10\n",
        "#   false_positive = [0]*10\n",
        "#   false_negative = [0]*10\n",
        "#   precision = [0]*10\n",
        "#   recall = [0]*10\n",
        "#   for i in range(m):\n",
        "#     total_classwise[testImageLabels[i]] += 1\n",
        "#     freq = [0]*10\n",
        "#     freq = np.array(freq)\n",
        "#     differenceArray = []\n",
        "#     print(\"Image\" + str(i) + \" test\")\n",
        "#     for j in range(n):\n",
        "#       differenceArray.append(MatchHistogram(testHistogramSet[i],trainHistogramSet[j]))\n",
        "#     differenceArray = np.array(differenceArray)\n",
        "#     maxIndices = np.argsort(differenceArray)\n",
        "#     for j in range(kk):\n",
        "#       freq[trainImageLabels[maxIndices[j]]] += 1\n",
        "#     x = freq.argmax()\n",
        "#     for j in range(10):\n",
        "#       if freq[x] == freq[j]:\n",
        "#         predicted[i]=j\n",
        "#         if testImageLabels[i] == j:\n",
        "#           positive +=1\n",
        "#           true_positive[j] +=1\n",
        "#           classwise[j] +=1\n",
        "#           break\n",
        "#         else:\n",
        "#           false_positive[j] +=1\n",
        "#       else:\n",
        "#         if testImageLabels[i] ==j:\n",
        "#           false_negative[j] +=1\n",
        "\n",
        "#   for j in range(10):\n",
        "#     classwise[j]=(classwise[j]/total_classwise[j])*100\n",
        "#     precision[j]=(true_positive[j])/(true_positive[j]+false_positive[j])\n",
        "#     recall[j]=(true_positive[j])/(true_positive[j]+false_negative[j])\n",
        "#     # print(positive)\n",
        "#   total_accuracy = (positive/m)*100\n",
        "#   return (total_accuracy,classwise,precision,recall,predicted)"
      ],
      "metadata": {
        "id": "ZUG-Lm9GQkSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateVisualDictionary(k,trainDescriptors):\n",
        "  print(\"On k = \" + str(k))\n",
        "  centroids = Initialize_centroid(k,trainDescriptors)\n",
        "  n = len(trainDescriptors)\n",
        "  clusterCentroid = [0]*n\n",
        "  for it in range(20):\n",
        "      print(\"Iteration \" + str(it) + \":\")\n",
        "      (clusterCentroid,centroids) = kMean_clustering(k,centroids,trainDescriptors)\n",
        "  centroids = Get_true_descriptor(centroids,trainDescriptors)\n",
        "  np.savetxt('./kmeanCentoids15.txt',centroids)\n",
        "  return centroids\n"
      ],
      "metadata": {
        "id": "qpBn8TM6RHR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Extracting Testing Data..\")\n",
        "testImageDescriptor = Get_features_set(testImageData)\n",
        "testDescriptors = Merge_features(testImageDescriptor)\n",
        "print(\"Extracting Training Data..\")\n",
        "trainImageDescriptor = Get_features_set(trainImageData)\n",
        "trainDescriptors = Merge_features(trainImageDescriptor)\n",
        "\n",
        "print(\"Creating Visual Dictionary..\")\n",
        "k = 15 #Explained in a pdf file\n",
        "centroids=CreateVisualDictionary(k,trainDescriptors)\n",
        "\n",
        "print(\"Forming histograms of training set..\")\n",
        "trainHistogramSet = ComputeHistogram(centroids,trainImageDescriptor)\n",
        "print(\"Forming histograms of testing set..\")\n",
        "testHistogramSet = ComputeHistogram(centroids,testImageDescriptor)\n",
        "\n",
        "countImagesTrain = Count_image_containing_visual_word(trainHistogramSet)\n",
        "countImagesTest = Count_image_containing_visual_word(testHistogramSet)\n",
        "\n",
        "print(\"Normalizing histograms of training set..\")\n",
        "trainHistogramSet = Normalize_histogram(trainHistogramSet,countImagesTrain)\n",
        "print(\"Normalizing histograms of testing set..\")\n",
        "testHistogramSet = Normalize_histogram(testHistogramSet,countImagesTest)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1TPm1h2pY_Q",
        "outputId": "07fbf7ca-f623-4de1-9d42-24b4b4bd4ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Testing Data..\n",
            "Extracting Training Data..\n",
            "Creating Visual Dictionary..\n",
            "On k = 15\n",
            "Iteration 0:\n",
            "Iteration 1:\n",
            "Iteration 2:\n",
            "Iteration 3:\n",
            "Iteration 4:\n",
            "Iteration 5:\n",
            "Iteration 6:\n",
            "Iteration 7:\n",
            "Iteration 8:\n",
            "Iteration 9:\n",
            "Iteration 10:\n",
            "Iteration 11:\n",
            "Iteration 12:\n",
            "Iteration 13:\n",
            "Iteration 14:\n",
            "Iteration 15:\n",
            "Iteration 16:\n",
            "Iteration 17:\n",
            "Iteration 18:\n",
            "Iteration 19:\n",
            "Forming histograms of training set..\n",
            "Forming histograms of testing set..\n",
            "Normalizing histograms of training set..\n",
            "Normalizing histograms of testing set..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing image sets..\")\n",
        "predicted = Accuracy(trainImageLabel,testImageLabel,trainHistogramSet,testHistogramSet,15)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_true = testImageLabel\n",
        "y_predict = predicted\n",
        "print(classification_report(y_true, y_predict, target_names=class_names))\n",
        "print(\"Overall accuracy => \")\n",
        "print(accuracy_score(y_true, y_predict))\n",
        "# print(\"Overall classification accuracy is: \"+str(total_accuracy))\n",
        "# for i in range(10):\n",
        "#   print(\"Class \"+str(i)+\" has accuracy: \",+(classwise[i]))\n",
        "#   print(\"Class \"+str(i)+\" has precision: \",+(precision[i]))\n",
        "#   print(\"Class \"+str(i)+\" has recall: \",+(recall[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYS8tRpoB7X2",
        "outputId": "31f80fcd-8b44-49bc-eae5-f33f264e6e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing image sets..\n",
            "Image0 test\n",
            "Image1 test\n",
            "Image2 test\n",
            "Image3 test\n",
            "Image4 test\n",
            "Image5 test\n",
            "Image6 test\n",
            "Image7 test\n",
            "Image8 test\n",
            "Image9 test\n",
            "Image10 test\n",
            "Image11 test\n",
            "Image12 test\n",
            "Image13 test\n",
            "Image14 test\n",
            "Image15 test\n",
            "Image16 test\n",
            "Image17 test\n",
            "Image18 test\n",
            "Image19 test\n",
            "Image20 test\n",
            "Image21 test\n",
            "Image22 test\n",
            "Image23 test\n",
            "Image24 test\n",
            "Image25 test\n",
            "Image26 test\n",
            "Image27 test\n",
            "Image28 test\n",
            "Image29 test\n",
            "Image30 test\n",
            "Image31 test\n",
            "Image32 test\n",
            "Image33 test\n",
            "Image34 test\n",
            "Image35 test\n",
            "Image36 test\n",
            "Image37 test\n",
            "Image38 test\n",
            "Image39 test\n",
            "Image40 test\n",
            "Image41 test\n",
            "Image42 test\n",
            "Image43 test\n",
            "Image44 test\n",
            "Image45 test\n",
            "Image46 test\n",
            "Image47 test\n",
            "Image48 test\n",
            "Image49 test\n",
            "Image50 test\n",
            "Image51 test\n",
            "Image52 test\n",
            "Image53 test\n",
            "Image54 test\n",
            "Image55 test\n",
            "Image56 test\n",
            "Image57 test\n",
            "Image58 test\n",
            "Image59 test\n",
            "Image60 test\n",
            "Image61 test\n",
            "Image62 test\n",
            "Image63 test\n",
            "Image64 test\n",
            "Image65 test\n",
            "Image66 test\n",
            "Image67 test\n",
            "Image68 test\n",
            "Image69 test\n",
            "Image70 test\n",
            "Image71 test\n",
            "Image72 test\n",
            "Image73 test\n",
            "Image74 test\n",
            "Image75 test\n",
            "Image76 test\n",
            "Image77 test\n",
            "Image78 test\n",
            "Image79 test\n",
            "Image80 test\n",
            "Image81 test\n",
            "Image82 test\n",
            "Image83 test\n",
            "Image84 test\n",
            "Image85 test\n",
            "Image86 test\n",
            "Image87 test\n",
            "Image88 test\n",
            "Image89 test\n",
            "Image90 test\n",
            "Image91 test\n",
            "Image92 test\n",
            "Image93 test\n",
            "Image94 test\n",
            "Image95 test\n",
            "Image96 test\n",
            "Image97 test\n",
            "Image98 test\n",
            "Image99 test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.25      0.25      0.25         8\n",
            "     Trouser       0.44      0.62      0.52        13\n",
            "    Pullover       0.67      0.43      0.52        14\n",
            "       Dress       0.00      0.00      0.00         9\n",
            "        Coat       0.50      0.50      0.50        10\n",
            "      Sandal       0.36      0.44      0.40         9\n",
            "       Shirt       0.50      0.38      0.43         8\n",
            "     Sneaker       0.50      0.45      0.48        11\n",
            "         Bag       0.50      0.58      0.54        12\n",
            "  Ankle boot       0.44      0.67      0.53         6\n",
            "\n",
            "    accuracy                           0.44       100\n",
            "   macro avg       0.42      0.43      0.42       100\n",
            "weighted avg       0.44      0.44      0.43       100\n",
            "\n",
            "Overall accuracy => \n",
            "0.44\n"
          ]
        }
      ]
    }
  ]
}